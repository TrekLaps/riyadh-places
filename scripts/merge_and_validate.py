#!/usr/bin/env python3
"""Merge new places + prices + validate + generate stats for riyadh-places project."""

import json
import re
import sys
from pathlib import Path
from collections import Counter

BASE = Path("/home/ubuntu/.openclaw/workspace/projects/riyadh-places")

# Required fields with defaults
REQUIRED_FIELDS = {
    "id": "",
    "name_ar": "",
    "name_en": "",
    "category": "",
    "category_ar": "",
    "category_en": "",
    "neighborhood": "",
    "neighborhood_en": "",
    "description_ar": "",
    "google_rating": 4.0,
    "price_level": "$$",
    "trending": False,
    "is_new": True,
    "sources": [],
    "google_maps_url": "",
    "district": "Ø§Ù„Ø±ÙŠØ§Ø¶",
    "perfect_for": [],
    "lat": 24.7136,
    "lng": 46.6753,
    "is_free": False,
    "audience": ["Ø§Ù„ÙƒÙ„"],
}

VALID_CATEGORIES_AR = {"Ù…Ø·Ø¹Ù…", "ÙƒØ§ÙÙŠÙ‡", "ØªØ±ÙÙŠÙ‡", "Ø­Ù„ÙˆÙŠØ§Øª", "ØªØ³ÙˆÙ‚", "ÙÙ†Ø§Ø¯Ù‚", "Ø·Ø¨ÙŠØ¹Ø©", "Ø´Ø§Ù„ÙŠÙ‡", "ÙØ¹Ø§Ù„ÙŠØ§Øª", "Ù…ØªØ§Ø­Ù", "Ù…ÙˆÙ„Ø§Øª"}
VALID_PRICE_LEVELS = {"$", "$$", "$$$", "$$$$", "Ù…Ø¬Ø§Ù†ÙŠ", "free", "Free"}

# Category mapping from english/research format
CATEGORY_MAP = {
    "restaurant": ("Ù…Ø·Ø¹Ù…", "Ù…Ø·Ø¹Ù…", "Restaurant"),
    "cafe": ("ÙƒØ§ÙÙŠÙ‡", "ÙƒØ§ÙÙŠÙ‡", "Cafe"),
    "entertainment": ("ØªØ±ÙÙŠÙ‡", "ØªØ±ÙÙŠÙ‡", "Entertainment"),
    "hotel": ("ÙÙ†Ø§Ø¯Ù‚", "ÙÙ†Ø§Ø¯Ù‚", "Hotel"),
    "mall": ("Ù…ÙˆÙ„Ø§Øª", "Ù…ÙˆÙ„Ø§Øª", "Mall"),
    "shopping": ("ØªØ³ÙˆÙ‚", "ØªØ³ÙˆÙ‚", "Shopping"),
    "dessert": ("Ø­Ù„ÙˆÙŠØ§Øª", "Ø­Ù„ÙˆÙŠØ§Øª", "Dessert"),
    "nature": ("Ø·Ø¨ÙŠØ¹Ø©", "Ø·Ø¨ÙŠØ¹Ø©", "Nature"),
    "events": ("ÙØ¹Ø§Ù„ÙŠØ§Øª", "ÙØ¹Ø§Ù„ÙŠØ§Øª", "Events"),
    "museum": ("Ù…ØªØ§Ø­Ù", "Ù…ØªØ§Ø­Ù", "Museum"),
    "chalet": ("Ø´Ø§Ù„ÙŠÙ‡", "Ø´Ø§Ù„ÙŠÙ‡", "Chalet"),
}

# Neighborhood mapping
NEIGHBORHOOD_MAP = {
    "KAFD": ("Ø­ÙŠ Ø§Ù„Ø¹Ù‚ÙŠÙ‚", "KAFD"),
    "kafd": ("Ø­ÙŠ Ø§Ù„Ø¹Ù‚ÙŠÙ‚", "KAFD"),
    "Al Olaya": ("Ø­ÙŠ Ø§Ù„Ø¹Ù„ÙŠØ§", "Al Olaya"),
    "Diriyah": ("Ø§Ù„Ø¯Ø±Ø¹ÙŠØ©", "Diriyah"),
    "Ø§Ù„Ø¯Ø±Ø¹ÙŠØ©": ("Ø§Ù„Ø¯Ø±Ø¹ÙŠØ©", "Diriyah"),
    "Ø§Ù„Ø³Ù„ÙŠÙ…Ø§Ù†ÙŠØ©": ("Ø­ÙŠ Ø§Ù„Ø³Ù„ÙŠÙ…Ø§Ù†ÙŠØ©", "Al Sulaimaniyah"),
    "Al Sulaimaniyah": ("Ø­ÙŠ Ø§Ù„Ø³Ù„ÙŠÙ…Ø§Ù†ÙŠØ©", "Al Sulaimaniyah"),
    "Ø§Ù„Ù†Ø®ÙŠÙ„": ("Ø­ÙŠ Ø§Ù„Ù†Ø®ÙŠÙ„", "Al Nakheel"),
    "Al Nakheel": ("Ø­ÙŠ Ø§Ù„Ù†Ø®ÙŠÙ„", "Al Nakheel"),
    "Ø­ÙŠ Ø§Ù„Ù…Ù„Ù‚Ø§": ("Ø­ÙŠ Ø§Ù„Ù…Ù„Ù‚Ø§", "Al Malqa"),
    "Al Malqa": ("Ø­ÙŠ Ø§Ù„Ù…Ù„Ù‚Ø§", "Al Malqa"),
    "Ø­Ø·ÙŠÙ†": ("Ø­ÙŠ Ø­Ø·ÙŠÙ†", "Hittin"),
    "Hittin": ("Ø­ÙŠ Ø­Ø·ÙŠÙ†", "Hittin"),
    "Ø§Ù„ÙŠØ§Ø³Ù…ÙŠÙ†": ("Ø­ÙŠ Ø§Ù„ÙŠØ§Ø³Ù…ÙŠÙ†", "Al Yasmin"),
    "Al Yasmin": ("Ø­ÙŠ Ø§Ù„ÙŠØ§Ø³Ù…ÙŠÙ†", "Al Yasmin"),
    "Ø§Ù„Ù…Ø±ÙˆØ¬": ("Ø­ÙŠ Ø§Ù„Ù…Ø±ÙˆØ¬", "Al Murooj"),
    "Ø§Ù„ÙˆØ±ÙˆØ¯": ("Ø­ÙŠ Ø§Ù„ÙˆØ±ÙˆØ¯", "Al Wurud"),
    "Ø§Ù„Ø±Ø­Ù…Ø§Ù†ÙŠØ©": ("Ø­ÙŠ Ø§Ù„Ø±Ø­Ù…Ø§Ù†ÙŠØ©", "Al Rahmaniyah"),
    "Ø§Ù„ØµØ­Ø§ÙØ©": ("Ø­ÙŠ Ø§Ù„ØµØ­Ø§ÙØ©", "Al Sahafah"),
    "Ø§Ù„Ø¹Ø§Ø±Ø¶": ("Ø­ÙŠ Ø§Ù„Ø¹Ø§Ø±Ø¶", "Al Arid"),
    "Ø§Ù„Ø±Ø¨ÙŠØ¹": ("Ø­ÙŠ Ø§Ù„Ø±Ø¨ÙŠØ¹", "Al Rabi"),
    "Ø§Ù„ØªØ¹Ø§ÙˆÙ†": ("Ø­ÙŠ Ø§Ù„ØªØ¹Ø§ÙˆÙ†", "Al Taawun"),
    "Ø§Ù„ØºØ¯ÙŠØ±": ("Ø­ÙŠ Ø§Ù„ØºØ¯ÙŠØ±", "Al Ghadir"),
    "Ø§Ù„Ù…Ø¹Ø°Ø±": ("Ø­ÙŠ Ø§Ù„Ù…Ø¹Ø°Ø±", "Al Mathar"),
    "Ø§Ù„Ù…Ù„Ø²": ("Ø­ÙŠ Ø§Ù„Ù…Ù„Ø²", "Al Malaz"),
}


def slugify(name):
    """Generate a URL-friendly slug from name_en."""
    s = name.lower().strip()
    s = re.sub(r'[^a-z0-9\s-]', '', s)
    s = re.sub(r'[\s]+', '-', s)
    s = re.sub(r'-+', '-', s)
    return s.strip('-')


def normalize_research_place(p):
    """Convert a research-format place to standard format."""
    cat_key = p.get("category", "restaurant").lower()
    cat_info = CATEGORY_MAP.get(cat_key, ("Ù…Ø·Ø¹Ù…", "Ù…Ø·Ø¹Ù…", "Restaurant"))
    
    name_en = p.get("name_en", "")
    neighborhood = p.get("neighborhood", "")
    
    # Resolve neighborhood
    nb_ar = neighborhood
    nb_en = neighborhood
    if neighborhood in NEIGHBORHOOD_MAP:
        nb_ar, nb_en = NEIGHBORHOOD_MAP[neighborhood]
    elif not any(c in neighborhood for c in "Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠ"):
        nb_en = neighborhood
        nb_ar = neighborhood
    
    place = {
        "id": slugify(name_en),
        "name_ar": p.get("name_ar", ""),
        "name_en": name_en,
        "category": cat_info[0],
        "category_ar": cat_info[1],
        "category_en": cat_info[2],
        "neighborhood": nb_ar,
        "neighborhood_en": nb_en,
        "description_ar": p.get("description_ar", ""),
        "google_rating": p.get("google_rating", 4.2),
        "price_level": p.get("price_level", "$$$"),
        "trending": p.get("trending", True),
        "is_new": True,
        "sources": [p.get("source", "research")] if isinstance(p.get("source"), str) else p.get("sources", ["research"]),
        "google_maps_url": p.get("google_maps_url", f"https://maps.google.com/?q={name_en.replace(' ', '+')}+Riyadh"),
        "district": p.get("district", "Ø§Ù„Ø±ÙŠØ§Ø¶"),
        "perfect_for": p.get("perfect_for", []),
        "lat": p.get("lat", 24.7136),
        "lng": p.get("lng", 46.6753),
        "is_free": p.get("is_free", False),
        "audience": p.get("audience", ["Ø§Ù„ÙƒÙ„"]),
    }
    return place


def ensure_fields(place):
    """Ensure all required fields exist with defaults."""
    for field, default in REQUIRED_FIELDS.items():
        if field not in place or place[field] is None:
            place[field] = default
    
    # Fix audience if string
    if isinstance(place.get("audience"), str):
        place["audience"] = [place["audience"]]
    
    # Fix sources if string
    if isinstance(place.get("sources"), str):
        place["sources"] = [place["sources"]]
    
    # Ensure id
    if not place["id"]:
        place["id"] = slugify(place.get("name_en", "unknown"))
    
    # Ensure google_maps_url
    if not place.get("google_maps_url"):
        name = place.get("name_en", "")
        place["google_maps_url"] = f"https://maps.google.com/?q={name.replace(' ', '+')}+Riyadh"
    
    return place


def validate_places(places):
    """Run comprehensive validation."""
    errors = []
    warnings = []
    
    # Check unique IDs
    ids = [p["id"] for p in places]
    id_counts = Counter(ids)
    for pid, count in id_counts.items():
        if count > 1:
            errors.append(f"Duplicate ID: '{pid}' appears {count} times")
    
    # Check unique name_en
    names = [p["name_en"].lower().strip() for p in places]
    name_counts = Counter(names)
    for name, count in name_counts.items():
        if count > 1:
            warnings.append(f"Duplicate name_en: '{name}' appears {count} times")
    
    for i, p in enumerate(places):
        prefix = f"[{p.get('id', f'index-{i}')}]"
        
        # Required fields
        if not p.get("name_ar"):
            errors.append(f"{prefix} Missing name_ar")
        if not p.get("name_en"):
            errors.append(f"{prefix} Missing name_en")
        
        # Rating 0-5
        rating = p.get("google_rating", 0)
        if not (0 <= rating <= 5):
            errors.append(f"{prefix} Invalid rating: {rating}")
        
        # Price level
        pl = p.get("price_level", "")
        if pl and pl not in VALID_PRICE_LEVELS:
            warnings.append(f"{prefix} Non-standard price_level: '{pl}'")
        
        # Category
        cat = p.get("category", "")
        if cat and cat not in VALID_CATEGORIES_AR:
            warnings.append(f"{prefix} Non-standard category: '{cat}'")
        
        # Lat/Lng bounds for Riyadh
        lat = p.get("lat", 0)
        lng = p.get("lng", 0)
        if lat and not (24.0 <= lat <= 25.5):
            warnings.append(f"{prefix} lat {lat} outside Riyadh range")
        if lng and not (46.0 <= lng <= 47.5):
            warnings.append(f"{prefix} lng {lng} outside Riyadh range")
        
        # Missing required fields
        for field in REQUIRED_FIELDS:
            if field not in p:
                warnings.append(f"{prefix} Missing field: {field}")
    
    return errors, warnings


def generate_light_version(places):
    """Generate places-light.json with essential fields only."""
    light_fields = ["id", "name_ar", "name_en", "category", "category_ar", "category_en",
                    "neighborhood", "neighborhood_en", "google_rating", "price_level",
                    "trending", "is_new", "lat", "lng", "is_free", "audience", "district"]
    light = []
    for p in places:
        lp = {k: p.get(k) for k in light_fields if k in p}
        light.append(lp)
    return light


def main():
    print("=" * 60)
    print("ğŸ”„ Riyadh Places - Merge & Validate")
    print("=" * 60)
    
    # 1. Load existing places
    with open(BASE / "data/places.json") as f:
        places = json.load(f)
    print(f"\nğŸ“¦ Existing places: {len(places)}")
    
    # Build index by name_en (lowercase)
    existing_names = {p["name_en"].lower().strip() for p in places}
    existing_names_ar = {p["name_ar"].strip() for p in places}
    existing_ids = {p["id"] for p in places}
    
    # 2. Load new-places-batch.json
    with open(BASE / "data/new-places-batch.json") as f:
        batch_places = json.load(f)
    print(f"ğŸ“¦ New batch places: {len(batch_places)}")
    
    # 3. Load research places
    with open(BASE / "research/new-places-discovered.json") as f:
        research_data = json.load(f)
    research_places = research_data.get("places", [])
    print(f"ğŸ“¦ Research places: {len(research_places)}")
    
    # 4. Merge batch places (already in standard format)
    added_batch = 0
    for p in batch_places:
        p = ensure_fields(p)
        name_key = p["name_en"].lower().strip()
        if name_key not in existing_names:
            # Ensure unique ID
            if p["id"] in existing_ids:
                p["id"] = p["id"] + "-2"
            places.append(p)
            existing_names.add(name_key)
            existing_ids.add(p["id"])
            added_batch += 1
        else:
            pass  # Skip duplicate
    print(f"âœ… Added from batch: {added_batch}")
    
    # 5. Merge research places (need normalization)
    added_research = 0
    for rp in research_places:
        p = normalize_research_place(rp)
        p = ensure_fields(p)
        name_key = p["name_en"].lower().strip()
        if name_key not in existing_names:
            if p["id"] in existing_ids:
                p["id"] = p["id"] + "-new"
            places.append(p)
            existing_names.add(name_key)
            existing_ids.add(p["id"])
            added_research += 1
    print(f"âœ… Added from research: {added_research}")
    
    total_added = added_batch + added_research
    print(f"\nğŸ“Š Total new places added: {total_added}")
    print(f"ğŸ“Š Total places now: {len(places)}")
    
    # 6. Ensure all places have required fields
    for p in places:
        ensure_fields(p)
    
    # 7. Load and index prices
    with open(BASE / "data/prices-initial.json") as f:
        prices = json.load(f)
    print(f"\nğŸ’° Prices entries: {len(prices)}")
    
    price_index = {}
    for pr in prices:
        key = pr.get("name_en", "").lower().strip()
        price_index[key] = pr
    
    # Match prices to places
    matched_prices = 0
    for p in places:
        key = p["name_en"].lower().strip()
        if key in price_index:
            matched_prices += 1
    print(f"ğŸ’° Prices matched to places: {matched_prices}/{len(prices)}")
    
    # Unmatched prices
    place_names_lower = {p["name_en"].lower().strip() for p in places}
    unmatched = [pr["name_en"] for pr in prices if pr["name_en"].lower().strip() not in place_names_lower]
    if unmatched:
        print(f"âš ï¸  Unmatched price entries: {unmatched}")
    
    # 8. Validation
    print("\n" + "=" * 60)
    print("ğŸ” VALIDATION REPORT")
    print("=" * 60)
    
    errors, warnings = validate_places(places)
    
    if errors:
        print(f"\nâŒ ERRORS ({len(errors)}):")
        for e in errors[:30]:
            print(f"   {e}")
        if len(errors) > 30:
            print(f"   ... and {len(errors) - 30} more")
    else:
        print("\nâœ… No errors found!")
    
    if warnings:
        print(f"\nâš ï¸  WARNINGS ({len(warnings)}):")
        for w in warnings[:30]:
            print(f"   {w}")
        if len(warnings) > 30:
            print(f"   ... and {len(warnings) - 30} more")
    else:
        print("\nâœ… No warnings!")
    
    # 9. Fix duplicate IDs
    seen_ids = {}
    for p in places:
        if p["id"] in seen_ids:
            seen_ids[p["id"]] += 1
            p["id"] = f"{p['id']}-{seen_ids[p['id']]}"
        else:
            seen_ids[p["id"]] = 1
    
    # 10. Statistics
    print("\n" + "=" * 60)
    print("ğŸ“Š STATISTICS")
    print("=" * 60)
    
    print(f"\nğŸ“ Total places: {len(places)}")
    
    # By category
    cats = Counter(p.get("category", "ØºÙŠØ± Ù…ØµÙ†Ù") for p in places)
    print("\nğŸ“‚ By Category:")
    for cat, count in cats.most_common():
        print(f"   {cat}: {count}")
    
    # By neighborhood (top 20)
    hoods = Counter(p.get("neighborhood", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯") for p in places)
    print("\nğŸ˜ï¸ Top 20 Neighborhoods:")
    for hood, count in hoods.most_common(20):
        print(f"   {hood}: {count}")
    
    # New places
    new_count = sum(1 for p in places if p.get("is_new"))
    print(f"\nğŸ†• New places (is_new=true): {new_count}")
    print(f"ğŸ’° Places with real prices: {matched_prices}")
    print(f"ğŸ”¥ Trending places: {sum(1 for p in places if p.get('trending'))}")
    print(f"ğŸ†“ Free places: {sum(1 for p in places if p.get('is_free'))}")
    
    # 11. Save merged places.json
    with open(BASE / "data/places.json", "w", encoding="utf-8") as f:
        json.dump(places, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ Saved places.json ({len(places)} places)")
    
    # 12. Save places-light.json
    light = generate_light_version(places)
    with open(BASE / "data/places-light.json", "w", encoding="utf-8") as f:
        json.dump(light, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ Saved places-light.json ({len(light)} places)")
    
    # 13. Save price index
    with open(BASE / "data/prices-index.json", "w", encoding="utf-8") as f:
        json.dump(price_index, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ Saved prices-index.json ({len(price_index)} entries)")
    
    # Summary
    print("\n" + "=" * 60)
    print("âœ… MERGE COMPLETE")
    print("=" * 60)
    print(f"   Total places: {len(places)}")
    print(f"   New added: {total_added}")
    print(f"   Errors: {len(errors)}")
    print(f"   Warnings: {len(warnings)}")
    
    return len(errors) == 0


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
